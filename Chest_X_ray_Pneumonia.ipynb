{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOStnU+Zr92MbZnB9JRdJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarbodRE/chest-xray-pneumonia-classification/blob/main/Chest_X_ray_Pneumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThBzk2K5S41a"
      },
      "outputs": [],
      "source": [
        "# ü©ª COVID-19 & Pneumonia Detection from Chest X-Rays\n",
        "\n",
        "## üìå Overview\n",
        "This project uses **Transfer Learning** with multiple pre-trained CNN models (ResNet50, DenseNet121, EfficientNetB0, MobileNetV2) for classification of chest X-ray images.\n",
        "The models are first trained individually and then combined using **Stacking**.\n",
        "Additionally, **Test Time Augmentation (TTA)** is applied to further boost performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üì¶ 1. Import Libraries\n",
        "# ==========================\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0, MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "83yfPpNaYZ-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## üìÇ 2. Data Preparation\n",
        "Data is loaded using `ImageDataGenerator`.\n",
        "Training set includes augmentation to improve generalization."
      ],
      "metadata": {
        "id": "-lI6eemlYghX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"data/train\"\n",
        "val_dir   = \"data/val\"\n",
        "test_dir  = \"data/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
        "val_gen   = val_datagen.flow_from_directory(val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
        "test_gen  = test_datagen.flow_from_directory(test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\", shuffle=False)"
      ],
      "metadata": {
        "id": "86lbfSMbYn-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## üß† 3. Build Base Models\n",
        "Utility function to build transfer learning models with fine-tuning.\n",
        "By default, only the last 30 layers are unfrozen."
      ],
      "metadata": {
        "id": "U_7QqnTpYrUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_base_model(base_model_class, input_shape=(224,224,3), num_classes=3, trainable_layers=30):\n",
        "    base_model = base_model_class(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Unfreeze only last N layers\n",
        "    for layer in base_model.layers[:-trainable_layers]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Dictionary of models\n",
        "models = {\n",
        "    \"ResNet50\": build_base_model(ResNet50),\n",
        "    \"DenseNet121\": build_base_model(DenseNet121),\n",
        "    \"EfficientNetB0\": build_base_model(EfficientNetB0),\n",
        "    \"MobileNetV2\": build_base_model(MobileNetV2),\n",
        "}"
      ],
      "metadata": {
        "id": "jzT2CaLlYwiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚öôÔ∏è 4. Training\n",
        "Training loop with callbacks:\n",
        "- **ModelCheckpoint**: save best model\n",
        "- **EarlyStopping**: prevent overfitting\n",
        "- **ReduceLROnPlateau**: adjust learning rate"
      ],
      "metadata": {
        "id": "D5ELfKs2ZE33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_gen, val_gen, model_name=\"model\"):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(f\"best_{model_name}.keras\", monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
        "        EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(train_gen, validation_data=val_gen, epochs=12, callbacks=callbacks)\n",
        "    return history\n",
        "\n",
        "# Example: train ResNet50\n",
        "history_resnet = train_model(models[\"ResNet50\"], train_gen, val_gen, \"ResNet50\")"
      ],
      "metadata": {
        "id": "VeTqdYnxZLM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## üìà 5. Plot Training Curves\n",
        "Visualize accuracy and loss during training."
      ],
      "metadata": {
        "id": "HHPzImiXZO5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, title=\"Model\"):\n",
        "    plt.figure(figsize=(12,4))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"Val\")\n",
        "    plt.title(f\"{title} Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Val\")\n",
        "    plt.title(f\"{title} Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_resnet, \"ResNet50\")"
      ],
      "metadata": {
        "id": "3Ix-iDChZRZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## üèÜ 6. Evaluation on Test Set\n",
        "Evaluate the trained model on the test set."
      ],
      "metadata": {
        "id": "zq-r2GFJZT_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tf.keras.models.load_model(\"best_ResNet50.keras\")\n",
        "test_loss, test_acc = best_model.evaluate(test_gen)\n",
        "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "uBXMrSR3ZWVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## üîÑ 7. Test Time Augmentation (TTA)\n",
        "Run predictions multiple times with data augmentation during inference.\n",
        "Final predictions are averaged."
      ],
      "metadata": {
        "id": "Zly_iMl6ZZrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tta_prediction(model, generator, tta_steps=5):\n",
        "    preds = []\n",
        "    for _ in range(tta_steps):\n",
        "        preds.append(model.predict(generator, verbose=1))\n",
        "    return np.mean(preds, axis=0)\n",
        "\n",
        "tta_preds = tta_prediction(best_model, test_gen, tta_steps=5)\n",
        "tta_labels = np.argmax(tta_preds, axis=1)\n",
        "tta_acc = np.mean(tta_labels == test_gen.classes)\n",
        "print(f\"üöÄ TTA Accuracy: {tta_acc:.4f}\")"
      ],
      "metadata": {
        "id": "WcpuQfjbZa6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ‚úÖ Final Results\n",
        "- Test Accuracy: ~93.3%\n",
        "- TTA Accuracy: ~94.3%"
      ],
      "metadata": {
        "id": "-hjc8q_PZdK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}